{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_function(x):\n",
    "    y = 1/(1 + np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(dims):\n",
    "    w = np.zeros((dims,1))\n",
    "    b = 0 \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x,y,w,b):\n",
    "    y_hat = sig_function(np.dot(x,w)+b)\n",
    "    cost = (-1/x.shape[0])*np.sum(y*np.log(y_hat)+\n",
    "                                 (1-y)*np.log(1-y_hat))\n",
    "    dw = np.dot(x.T,(y_hat-y))/x.shape[0]\n",
    "    db = np.sum(y_hat-y)/x.shape[0]\n",
    "    cost = np.squeeze(cost)\n",
    "    return y_hat,cost,dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_train(x,y,learning_rate,epochs):\n",
    "    w,b = initialize(x.shape[1])\n",
    "    cost_list = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        y_hat,cost,dw,db = loss_function(x,y,w,b)\n",
    "        w = w-learning_rate*dw\n",
    "        b = b-learning_rate*db\n",
    "\n",
    "        # 记录损失\n",
    "        if i % 100 == 0:\n",
    "            cost_list.append(cost)   \n",
    "        # 打印训练过程中的损失 \n",
    "        if i % 100 == 0:\n",
    "            print('epoch %d cost %f' % (i, cost)) \n",
    "    # 保存参数\n",
    "    params = {            \n",
    "        'W': w,            \n",
    "        'b': b\n",
    "    }        \n",
    "    # 保存梯度\n",
    "    grads = {            \n",
    "        'dW': dw,            \n",
    "        'db': db\n",
    "    }           \n",
    "    return cost_list, params, grads        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, params):\n",
    "    y_prediction = sig_function(np.dot(x, params['W']) + params['b']) \n",
    "    for i in range(len(y_prediction)):        \n",
    "        if y_prediction[i] > 0.5:\n",
    "            y_prediction[i] = 1\n",
    "        else:\n",
    "            y_prediction[i] = 0\n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_classification\n",
    "X,labels=make_classification(n_samples=100, n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=2)\n",
    "rng=np.random.RandomState(2)\n",
    "X+=2*rng.uniform(size=X.shape)\n",
    "\n",
    "unique_lables=set(labels)\n",
    "colors=plt.cm.Spectral(np.linspace(0, 1, len(unique_lables)))\n",
    "for k, col in zip(unique_lables, colors):\n",
    "    x_k=X[labels==k]\n",
    "    plt.plot(x_k[:, 0], x_k[:, 1], 'o', markerfacecolor=col, markeredgecolor=\"k\",\n",
    "             markersize=14)\n",
    "plt.title('data by make_classification()')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train= (90, 2)\n",
      "X_test= (10, 2)\n",
      "y_train= (90, 1)\n",
      "y_test= (10, 1)\n"
     ]
    }
   ],
   "source": [
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], labels[:offset]\n",
    "X_test, y_test = X[offset:], labels[offset:]\n",
    "y_train = y_train.reshape((-1,1))\n",
    "y_test = y_test.reshape((-1,1))\n",
    "\n",
    "print('X_train=', X_train.shape)\n",
    "print('X_test=', X_test.shape)\n",
    "print('y_train=', y_train.shape)\n",
    "print('y_test=', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cost 0.693147\n",
      "epoch 100 cost 0.554066\n",
      "epoch 200 cost 0.480953\n",
      "epoch 300 cost 0.434738\n",
      "epoch 400 cost 0.402395\n",
      "epoch 500 cost 0.378275\n",
      "epoch 600 cost 0.359468\n",
      "epoch 700 cost 0.344313\n",
      "epoch 800 cost 0.331783\n",
      "epoch 900 cost 0.321216\n"
     ]
    }
   ],
   "source": [
    "cost_list, params, grads = logistic_train(X_train, y_train, 0.01, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_prediction = predict(X_test, params)\n",
    "print(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test,y_pre):\n",
    "    count = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == y_pre[i]:\n",
    "            count +=1\n",
    "    accu = count/len(y_test)\n",
    "    return accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = accuracy(y_test,y_prediction)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_classification\n",
    "\n",
    "class logistic_regression():    \n",
    "    def __init__(self):        \n",
    "        pass\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        z = 1 / (1 + np.exp(-x))        \n",
    "        return z    \n",
    "        \n",
    "    def initialize_params(self, dims):\n",
    "        W = np.zeros((dims, 1))\n",
    "        b = 0\n",
    "        return W, b    \n",
    "    \n",
    "    def logistic(self, X, y, W, b):\n",
    "        num_train = X.shape[0]\n",
    "        num_feature = X.shape[1]\n",
    "\n",
    "        a = self.sigmoid(np.dot(X, W) + b)\n",
    "        cost = -1 / num_train * np.sum(y * np.log(a) + (1 - y) * np.log(1 - a))\n",
    "\n",
    "        dW = np.dot(X.T, (a - y)) / num_train\n",
    "        db = np.sum(a - y) / num_train\n",
    "        cost = np.squeeze(cost)        \n",
    "        return a, cost, dW, db    \n",
    "        \n",
    "    def logistic_train(self, X, y, learning_rate, epochs):\n",
    "        W, b = self.initialize_params(X.shape[1])\n",
    "        cost_list = []        \n",
    "        for i in range(epochs):\n",
    "            a, cost, dW, db = self.logistic(X, y, W, b)\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db            \n",
    "            if i % 100 == 0:\n",
    "                cost_list.append(cost)            \n",
    "            if i % 100 == 0:\n",
    "                print('epoch %d cost %f' % (i, cost))\n",
    "\n",
    "        params = {\n",
    "            'W': W, \n",
    "            'b': b\n",
    "        }\n",
    "        grads = {            \n",
    "            'dW': dW,            \n",
    "            'db': db\n",
    "        }        \n",
    "        \n",
    "        return cost_list, params, grads    \n",
    "        \n",
    "    def predict(self, X, params):\n",
    "        y_prediction = self.sigmoid(np.dot(X, params['W']) + params['b'])        \n",
    "        for i in range(len(y_prediction)):            \n",
    "            if y_prediction[i] > 0.5:\n",
    "                y_prediction[i] = 1\n",
    "            else:\n",
    "                y_prediction[i] = 0\n",
    "\n",
    "        return y_prediction    \n",
    "            \n",
    "    def accuracy(self, y_test, y_pred):\n",
    "        correct_count = 0\n",
    "        for i in range(len(y_test)):            \n",
    "            for j in range(len(y_pred)):                \n",
    "                if y_test[i] == y_pred[j] and i == j:\n",
    "                    correct_count += 1\n",
    "\n",
    "        accuracy_score = correct_count / len(y_test)        \n",
    "        return accuracy_score    \n",
    "        \n",
    "    def create_data(self):\n",
    "        X, labels = make_classification(n_samples=100, n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=2)\n",
    "        labels = labels.reshape((-1, 1))\n",
    "        offset = int(X.shape[0] * 0.9)\n",
    "        X_train, y_train = X[:offset], labels[:offset]\n",
    "        X_test, y_test = X[offset:], labels[offset:]        \n",
    "        return X_train, y_train, X_test, y_test    \n",
    "        \n",
    "    def plot_logistic(self, X_train, y_train, params):\n",
    "        n = X_train.shape[0]\n",
    "        xcord1 = []\n",
    "        ycord1 = []\n",
    "        xcord2 = []\n",
    "        ycord2 = []        \n",
    "        for i in range(n):            \n",
    "            if y_train[i] == 1:\n",
    "                xcord1.append(X_train[i][0])\n",
    "                ycord1.append(X_train[i][1])            \n",
    "            else:\n",
    "                xcord2.append(X_train[i][0])\n",
    "                ycord2.append(X_train[i][1])\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(xcord1, ycord1, s=32, c='red')\n",
    "        ax.scatter(xcord2, ycord2, s=32, c='green')\n",
    "        x = np.arange(-1.5, 3, 0.1)\n",
    "        y = (-params['b'] - params['W'][0] * x) / params['W'][1]\n",
    "        ax.plot(x, y)\n",
    "        plt.xlabel('X1')\n",
    "        plt.ylabel('X2')\n",
    "       plt.show()\n",
    "\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    model = logistic_regression()\n",
    "    X_train, y_train, X_test, y_test = model.create_data()\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    cost_list, params, grads = model.logistic_train(X_train, y_train, 0.01, 1000)\n",
    "    print(params)\n",
    "    y_train_pred = model.predict(X_train, params)\n",
    "    accuracy_score_train = model.accuracy(y_train, y_train_pred)\n",
    "    print('train accuracy is:', accuracy_score_train)\n",
    "    y_test_pred = model.predict(X_test, params)\n",
    "    accuracy_score_test = model.accuracy(y_test, y_test_pred)\n",
    "    print('test accuracy is:', accuracy_score_test)\n",
    "    model.plot_logistic(X_train, y_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
